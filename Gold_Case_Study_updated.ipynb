{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gold Case Study-updated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/Machine-Learning/blob/master/Gold_Case_Study_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TBn1CjquH0Tw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing Required Packages"
      ]
    },
    {
      "metadata": {
        "id": "CVnm8K03HvqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1263
        },
        "outputId": "74a4b3a4-8a0f-49b0-d3fc-2be0ddd54d55"
      },
      "cell_type": "code",
      "source": [
        "# Set up environment and download course-v3\n",
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai\n",
        "!pip install fastprogress\n",
        "!pip install pathlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181128-cp36-cp36m-linux_x86_64.whl (576.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.6MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6281a000 @  0x7f6c59d642a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181128\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/13/dfb1683762bc2e2ee0503e08e812a164f710a8b919c050fd5838c150f3ca/fastai-1.0.29-py3-none-any.whl (131kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 3.6MB/s \n",
            "\u001b[?25hCollecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Requirement already satisfied: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Collecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Collecting fastprogress>=0.1.16 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/93/b35cabbab4d25a2fdc5cd196114fbe1160451df5cf1459a80781893f3b0f/fastprogress-0.1.16-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 30.1MB/s \n",
            "\u001b[?25hCollecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: spacy==2.0.16 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.16)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.0.0)\n",
            "Requirement already satisfied: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2018.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (4.28.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.0.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (2.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.4.3.2)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.2.8.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.9.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "\u001b[31mtorchvision-nightly 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numexpr, dataclasses, fastprogress, bottleneck, torchvision-nightly, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.29 fastprogress-0.1.16 numexpr-2.6.8 torchvision-nightly-0.2.1\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.6/dist-packages (0.1.16)\n",
            "Collecting pathlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathlib\n",
            "  Running setup.py bdist_wheel for pathlib ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
            "Successfully built pathlib\n",
            "Installing collected packages: pathlib\n",
            "Successfully installed pathlib-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SMiWMiwlH9wX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " !curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biF4Fc5AH_GV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import *\n",
        "from fastai.tabular import *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JjVc47GxSnST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNZwLYN0VBV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb21df1b-77a2-434a-d978-ae41c1928bc1"
      },
      "cell_type": "code",
      "source": [
        "# check the directory of the data \n",
        "!ls -d $PWD/*"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/course-v3  /content/data  /content/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qe1mzLqtR1OF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading in Data"
      ]
    },
    {
      "metadata": {
        "id": "EZE1nXT4SMkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "using a function to concatenate csvs "
      ]
    },
    {
      "metadata": {
        "id": "5hO6VZGsSsGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/content/data/'\n",
        "os.makedirs(path, exist_ok=True)\n",
        "#path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGF-sDadS7di",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddef046b-b8ef-4e8b-e1ab-c6d9da8795b9"
      },
      "cell_type": "code",
      "source": [
        "!ls {path}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " C1_Comdty_t.csv   chicago_weather_t.csv  'GC1 Comdty_t.csv'   us_macro_t.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cN2OO0ggTDra",
        "colab_type": "code",
        "outputId": "fec8d17e-c22d-44f3-ff7e-f878e6cd3356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check the directory of the data \n",
        "!ls -d $PWD/*"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/course-v3  /content/data  /content/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VnoWuqCUSSeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "table_names = ['C1_Comdty_t', 'GC1 Comdty_t', 'chicago_weather_t', 'us_macro_t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVx4No0VSbhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tables = [pd.read_csv(f'{path}{fname}.csv', low_memory=False) for fname in table_names]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeJ04QfBb-GS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Naming tables"
      ]
    },
    {
      "metadata": {
        "id": "U6P_0sa4bteZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "C1 = tables[0]\n",
        "GC1 = tables[1]\n",
        "chicago_weather = tables[2]\n",
        "us_macro = tables[3]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qo9DpvQ6cKtW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vpkf4BOzVZKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "metadata": {
        "id": "AmfxzwKXSdFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0OzteSEYPI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pandas-summary\n",
        "from pandas_summary import DataFrameSummary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NtB3jJXkVd58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# looking at all data\n",
        "for t in tables: display(t.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nnhZD3LVfch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# looking at summarized data\n",
        "for t in tables: display(t.describe(include='all'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5mcalcDall6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Feature Engineering"
      ]
    },
    {
      "metadata": {
        "id": "9w5d3ZMwfpib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "creating Month field for all tables"
      ]
    },
    {
      "metadata": {
        "id": "78FYoxEzftXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GC1['Month'] = pd.DatetimeIndex(GC1['GC1 Comdty']).month\n",
        "C1['Month'] = pd.DatetimeIndex(C1['C 1 Comdty']).month\n",
        "chicago_weather['Month'] = pd.DatetimeIndex(chicago_weather['DATE']).month\n",
        "us_macro['Month'] = pd.DatetimeIndex(us_macro['date']).month"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTBrMJU4gtNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "creating year field for year to join chicago_weather and us_macro"
      ]
    },
    {
      "metadata": {
        "id": "iFl3XIWsf_z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# us_macro['Year'] =  pd.DatetimeIndex(us_macro['date']).year\n",
        "# chicago_weather['Year'] = pd.DatetimeIndex(chicago_weather['DATE']).year\n",
        "\n",
        "chicago_weather['Month_Year'] = pd.to_datetime(chicago_weather['DATE']).dt.to_period('M')\n",
        "us_macro['Month_Year'] = pd.to_datetime(us_macro['date']).dt.to_period('M')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3iv1gnybAYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Join function to join pandas dataframes\n",
        "\n",
        "We don't use an inner join because we won't want to delete any values (yet), we just want them to appear as null, so we can analyze them later"
      ]
    },
    {
      "metadata": {
        "id": "8kba5_s1Z_IM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def join_df(left, right, left_on, right_on=None, suffix='_y'):\n",
        "    if right_on is None: right_on = left_on\n",
        "    return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
        "                      suffixes=(\"\", suffix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ToubLN69bDcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# joining corn and gold based on date\n",
        "gold = join_df(GC1,C1, 'GC1 Comdty', 'C 1 Comdty', suffix = '_corn')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5IxJVfJKcUkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#gold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Av8Vw6-Vhyzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# joining chicago weather and us macro\n",
        "us_stats = join_df(chicago_weather, us_macro, 'Month_Year', 'Month_Year', suffix = '_us')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQney5fpiCkh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#us_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c8AR1HVsjQxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, combine the 2 tables together"
      ]
    },
    {
      "metadata": {
        "id": "qA3mV3VHcZIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_data = join_df(gold, us_stats, 'GC1 Comdty', 'DATE', suffix = '_y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yMJpYqzGc6pa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concat_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LH3zHznHkMjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving data\n",
        "#concat_data.to_csv('concat_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xTPWcu6kkr4x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we want to drop all duplicate/useless information"
      ]
    },
    {
      "metadata": {
        "id": "ABw_PPXYkwMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean = concat_data.drop(['Unnamed: 0', 'Bid', 'Ask', 'Unnamed: 0_corn', 'Unnamed: 0.1',\n",
        "                 'C 1 Comdty', 'Bid_corn', 'Ask_corn', 'Month_corn', 'Unnamed: 0_y', 'LATITUDE', 'LONGITUDE',\n",
        "                 'ELEVATION', 'DATE', 'Month_y', 'Month_Year', 'Unnamed: 0_us', 'date', 'Month_us'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWRaiOrnkyyl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean = concat_clean.rename(columns={'GC1 Comdty': 'Date', 'Last':'Price'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RD6T1hRspaNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Optional: remove any instances where there is no price for gold"
      ]
    },
    {
      "metadata": {
        "id": "4BGXewGDpdKh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concat_clean.dropna(subset=['Price'])\n",
        "\n",
        "#concat_clean = concat_clean.dropna(subset=['Price'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lo8KmWt4rJ_C",
        "colab_type": "code",
        "outputId": "afa95c7e-7cf2-4ed4-e044-a185c9837d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "concat_clean.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_Interest</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Last_corn</th>\n",
              "      <th>High_corn</th>\n",
              "      <th>Low_corn</th>\n",
              "      <th>Volume_corn</th>\n",
              "      <th>Open_Interest_corn</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>gdp</th>\n",
              "      <th>cpi</th>\n",
              "      <th>int</th>\n",
              "      <th>nettrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/6/2000</td>\n",
              "      <td>282.4</td>\n",
              "      <td>282.8</td>\n",
              "      <td>280.2</td>\n",
              "      <td>26026.0</td>\n",
              "      <td>67505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>203.00</td>\n",
              "      <td>37490.0</td>\n",
              "      <td>216368.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/7/2000</td>\n",
              "      <td>282.9</td>\n",
              "      <td>284.5</td>\n",
              "      <td>282.0</td>\n",
              "      <td>19396.0</td>\n",
              "      <td>68731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202.50</td>\n",
              "      <td>46637.0</td>\n",
              "      <td>219250.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/10/2000</td>\n",
              "      <td>282.7</td>\n",
              "      <td>283.9</td>\n",
              "      <td>281.8</td>\n",
              "      <td>11612.0</td>\n",
              "      <td>66778.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>208.50</td>\n",
              "      <td>209.25</td>\n",
              "      <td>204.75</td>\n",
              "      <td>47788.0</td>\n",
              "      <td>218442.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/11/2000</td>\n",
              "      <td>284.4</td>\n",
              "      <td>285.3</td>\n",
              "      <td>281.9</td>\n",
              "      <td>30928.0</td>\n",
              "      <td>64731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>207.25</td>\n",
              "      <td>209.25</td>\n",
              "      <td>206.25</td>\n",
              "      <td>41233.0</td>\n",
              "      <td>218977.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/12/2000</td>\n",
              "      <td>283.7</td>\n",
              "      <td>285.0</td>\n",
              "      <td>282.5</td>\n",
              "      <td>13678.0</td>\n",
              "      <td>64629.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>215.50</td>\n",
              "      <td>216.75</td>\n",
              "      <td>206.75</td>\n",
              "      <td>122388.0</td>\n",
              "      <td>229517.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Price   High    Low   Volume  Open_Interest  Month  Year  \\\n",
              "0   1/6/2000  282.4  282.8  280.2  26026.0        67505.0      1  2000   \n",
              "1   1/7/2000  282.9  284.5  282.0  19396.0        68731.0      1  2000   \n",
              "2  1/10/2000  282.7  283.9  281.8  11612.0        66778.0      1  2000   \n",
              "3  1/11/2000  284.4  285.3  281.9  30928.0        64731.0      1  2000   \n",
              "4  1/12/2000  283.7  285.0  282.5  13678.0        64629.0      1  2000   \n",
              "\n",
              "   Last_corn  High_corn  Low_corn  Volume_corn  Open_Interest_corn  TAVG  gdp  \\\n",
              "0     203.75     205.75    203.00      37490.0            216368.0  30.0  NaN   \n",
              "1        NaN        NaN    202.50      46637.0            219250.0  24.0  NaN   \n",
              "2     208.50     209.25    204.75      47788.0            218442.0  40.0  NaN   \n",
              "3     207.25     209.25    206.25      41233.0            218977.0   NaN  NaN   \n",
              "4     215.50     216.75    206.75     122388.0            229517.0  29.0  NaN   \n",
              "\n",
              "   cpi  int  nettrade  \n",
              "0  NaN  NaN       NaN  \n",
              "1  NaN  NaN       NaN  \n",
              "2  NaN  NaN       NaN  \n",
              "3  NaN  NaN       NaN  \n",
              "4  NaN  NaN       NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "OXKIADNlmxbx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save cleaned csv"
      ]
    },
    {
      "metadata": {
        "id": "v0cqC4x0mvFD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean.to_csv('concat_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJxdzfnJoRCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dealing with NaNs"
      ]
    },
    {
      "metadata": {
        "id": "YMrJ6lh3sDu6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Possible Strategies\n",
        "- replace NA with a value not seen in the dataset\n",
        "- replace NA with an avg/median value `df.fillna(df.mean(), inplace=True`)\n",
        "- replace NA with last seen value `df.fillna(method='ffill', inplace=True)`"
      ]
    },
    {
      "metadata": {
        "id": "u-bHBqcluJNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We try using last strategy (fill in with last seen value)\n",
        "\n",
        "First we want to fill in the 1st row for us_macro stats"
      ]
    },
    {
      "metadata": {
        "id": "UXhTXztcstEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['gdp'][0] = 9697.2\n",
        "concat_clean['cpi'][0] = 0.870492853\n",
        "concat_clean['int'][0] = 5.73\n",
        "concat_clean['nettrade'][0] = -29930"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXbCjrvtsi5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concat_clean = concat_clean.fillna(concat_clean.mean.astype(np.int32))\n",
        "\n",
        "concat_clean.fillna(method='ffill', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccpP0qnhs1vn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concat_clean.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17nAXlFtvwnG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "saving data"
      ]
    },
    {
      "metadata": {
        "id": "KPywYO6ys8KG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean.to_csv('concat_clean_fillna.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9UWQqzABvy5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55302458-5866-40ce-d696-632352787c1e"
      },
      "cell_type": "code",
      "source": [
        "len(concat_clean)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "y84MwCwwv1Yv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "after cleaning the data, we are left with 1396 observations of 17 features"
      ]
    },
    {
      "metadata": {
        "id": "-cH8TlMVvict",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Engineering New Features"
      ]
    },
    {
      "metadata": {
        "id": "mCax0JolJOzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "changing price to float32"
      ]
    },
    {
      "metadata": {
        "id": "HA0cRArtJRGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Price'] = concat_clean['Price'].astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKzJgUaNGuin",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating day of week feature"
      ]
    },
    {
      "metadata": {
        "id": "kGFYIG2OGwFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Date-Time'] = pd.to_datetime(concat_clean['Date'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4G1i4q00Hf-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Weekday'] = concat_clean['Date-Time'].dt.dayofweek"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4yKdjPiHus8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# deleting date-time\n",
        "concat_clean = concat_clean.drop(['Date-Time'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WK4Hq2QHpZC",
        "colab_type": "code",
        "outputId": "4caa170b-57f2-4db2-e22f-11c503ebf3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "concat_clean.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_Interest</th>\n",
              "      <th>Month</th>\n",
              "      <th>Last_corn</th>\n",
              "      <th>High_corn</th>\n",
              "      <th>Low_corn</th>\n",
              "      <th>Volume_corn</th>\n",
              "      <th>Open_Interest_corn</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>gdp</th>\n",
              "      <th>cpi</th>\n",
              "      <th>int</th>\n",
              "      <th>nettrade</th>\n",
              "      <th>Weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/6/2000</td>\n",
              "      <td>282.399994</td>\n",
              "      <td>282.8</td>\n",
              "      <td>280.2</td>\n",
              "      <td>26026.0</td>\n",
              "      <td>67505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>203.00</td>\n",
              "      <td>37490.0</td>\n",
              "      <td>216368.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/7/2000</td>\n",
              "      <td>282.899994</td>\n",
              "      <td>284.5</td>\n",
              "      <td>282.0</td>\n",
              "      <td>19396.0</td>\n",
              "      <td>68731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>202.50</td>\n",
              "      <td>46637.0</td>\n",
              "      <td>219250.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/10/2000</td>\n",
              "      <td>282.700012</td>\n",
              "      <td>283.9</td>\n",
              "      <td>281.8</td>\n",
              "      <td>11612.0</td>\n",
              "      <td>66778.0</td>\n",
              "      <td>1</td>\n",
              "      <td>208.50</td>\n",
              "      <td>209.25</td>\n",
              "      <td>204.75</td>\n",
              "      <td>47788.0</td>\n",
              "      <td>218442.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/11/2000</td>\n",
              "      <td>284.399994</td>\n",
              "      <td>285.3</td>\n",
              "      <td>281.9</td>\n",
              "      <td>30928.0</td>\n",
              "      <td>64731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>207.25</td>\n",
              "      <td>209.25</td>\n",
              "      <td>206.25</td>\n",
              "      <td>41233.0</td>\n",
              "      <td>218977.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/12/2000</td>\n",
              "      <td>283.700012</td>\n",
              "      <td>285.0</td>\n",
              "      <td>282.5</td>\n",
              "      <td>13678.0</td>\n",
              "      <td>64629.0</td>\n",
              "      <td>1</td>\n",
              "      <td>215.50</td>\n",
              "      <td>216.75</td>\n",
              "      <td>206.75</td>\n",
              "      <td>122388.0</td>\n",
              "      <td>229517.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date       Price   High    Low   Volume  Open_Interest  Month  \\\n",
              "0   1/6/2000  282.399994  282.8  280.2  26026.0        67505.0      1   \n",
              "1   1/7/2000  282.899994  284.5  282.0  19396.0        68731.0      1   \n",
              "2  1/10/2000  282.700012  283.9  281.8  11612.0        66778.0      1   \n",
              "3  1/11/2000  284.399994  285.3  281.9  30928.0        64731.0      1   \n",
              "4  1/12/2000  283.700012  285.0  282.5  13678.0        64629.0      1   \n",
              "\n",
              "   Last_corn  High_corn  Low_corn  Volume_corn  Open_Interest_corn  TAVG  \\\n",
              "0     203.75     205.75    203.00      37490.0            216368.0  30.0   \n",
              "1     203.75     205.75    202.50      46637.0            219250.0  24.0   \n",
              "2     208.50     209.25    204.75      47788.0            218442.0  40.0   \n",
              "3     207.25     209.25    206.25      41233.0            218977.0  40.0   \n",
              "4     215.50     216.75    206.75     122388.0            229517.0  29.0   \n",
              "\n",
              "      gdp       cpi   int  nettrade  Weekday  \n",
              "0  9697.2  0.870493  5.73  -29930.0        3  \n",
              "1  9697.2  0.870493  5.73  -29930.0        4  \n",
              "2  9697.2  0.870493  5.73  -29930.0        0  \n",
              "3  9697.2  0.870493  5.73  -29930.0        1  \n",
              "4  9697.2  0.870493  5.73  -29930.0        2  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "3NechewH3-Yq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(OPTIONAL)add Year+Month as feature"
      ]
    },
    {
      "metadata": {
        "id": "VPJbxhMvvhgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concat_clean['Month_Year'] = pd.to_datetime(concat_clean['Date']).dt.to_period('M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2dhcLwV4MMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "6cc505a8-e87a-4507-ba33-0f237b3dfddf"
      },
      "cell_type": "code",
      "source": [
        "concat_clean.describe(include='all')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_Interest</th>\n",
              "      <th>Month</th>\n",
              "      <th>Last_corn</th>\n",
              "      <th>High_corn</th>\n",
              "      <th>Low_corn</th>\n",
              "      <th>Volume_corn</th>\n",
              "      <th>Open_Interest_corn</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>gdp</th>\n",
              "      <th>cpi</th>\n",
              "      <th>int</th>\n",
              "      <th>nettrade</th>\n",
              "      <th>Weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1396</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.00000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "      <td>1396.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1396</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>3/24/2005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>337.893188</td>\n",
              "      <td>339.867622</td>\n",
              "      <td>335.943481</td>\n",
              "      <td>17583.46490</td>\n",
              "      <td>48992.016476</td>\n",
              "      <td>6.274355</td>\n",
              "      <td>224.952364</td>\n",
              "      <td>227.177113</td>\n",
              "      <td>222.804979</td>\n",
              "      <td>32740.053009</td>\n",
              "      <td>150963.580946</td>\n",
              "      <td>49.231375</td>\n",
              "      <td>10839.078510</td>\n",
              "      <td>0.930911</td>\n",
              "      <td>2.844427</td>\n",
              "      <td>-39704.636103</td>\n",
              "      <td>2.017908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>60.512489</td>\n",
              "      <td>60.925923</td>\n",
              "      <td>59.887781</td>\n",
              "      <td>23267.96006</td>\n",
              "      <td>62312.826674</td>\n",
              "      <td>3.386027</td>\n",
              "      <td>28.609813</td>\n",
              "      <td>29.061847</td>\n",
              "      <td>27.950594</td>\n",
              "      <td>20566.028123</td>\n",
              "      <td>104003.747021</td>\n",
              "      <td>19.798379</td>\n",
              "      <td>789.261278</td>\n",
              "      <td>0.034888</td>\n",
              "      <td>1.951549</td>\n",
              "      <td>9664.234832</td>\n",
              "      <td>1.399578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>255.100006</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>174.750000</td>\n",
              "      <td>175.750000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>9697.200000</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>-58819.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>279.200012</td>\n",
              "      <td>280.475000</td>\n",
              "      <td>277.700000</td>\n",
              "      <td>115.75000</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>207.750000</td>\n",
              "      <td>204.750000</td>\n",
              "      <td>18599.250000</td>\n",
              "      <td>55380.250000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>10221.600000</td>\n",
              "      <td>0.907873</td>\n",
              "      <td>1.260000</td>\n",
              "      <td>-46484.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>320.899994</td>\n",
              "      <td>322.950000</td>\n",
              "      <td>319.600000</td>\n",
              "      <td>1993.50000</td>\n",
              "      <td>11953.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>215.500000</td>\n",
              "      <td>31581.500000</td>\n",
              "      <td>157563.500000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>10572.300000</td>\n",
              "      <td>0.927843</td>\n",
              "      <td>1.760000</td>\n",
              "      <td>-36519.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>398.025002</td>\n",
              "      <td>401.075000</td>\n",
              "      <td>394.600000</td>\n",
              "      <td>31402.75000</td>\n",
              "      <td>83600.750000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>237.750000</td>\n",
              "      <td>239.750000</td>\n",
              "      <td>235.500000</td>\n",
              "      <td>43074.750000</td>\n",
              "      <td>225783.500000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>11447.800000</td>\n",
              "      <td>0.958054</td>\n",
              "      <td>4.210000</td>\n",
              "      <td>-31150.750000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>456.000000</td>\n",
              "      <td>456.500000</td>\n",
              "      <td>451.500000</td>\n",
              "      <td>112943.00000</td>\n",
              "      <td>253662.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>330.500000</td>\n",
              "      <td>335.250000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>180995.000000</td>\n",
              "      <td>394859.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>12589.600000</td>\n",
              "      <td>0.997994</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>-26839.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date        Price         High          Low        Volume  \\\n",
              "count        1396  1396.000000  1396.000000  1396.000000    1396.00000   \n",
              "unique       1396          NaN          NaN          NaN           NaN   \n",
              "top     3/24/2005          NaN          NaN          NaN           NaN   \n",
              "freq            1          NaN          NaN          NaN           NaN   \n",
              "mean          NaN   337.893188   339.867622   335.943481   17583.46490   \n",
              "std           NaN    60.512489    60.925923    59.887781   23267.96006   \n",
              "min           NaN   255.100006   255.000000   255.000000       1.00000   \n",
              "25%           NaN   279.200012   280.475000   277.700000     115.75000   \n",
              "50%           NaN   320.899994   322.950000   319.600000    1993.50000   \n",
              "75%           NaN   398.025002   401.075000   394.600000   31402.75000   \n",
              "max           NaN   456.000000   456.500000   451.500000  112943.00000   \n",
              "\n",
              "        Open_Interest        Month    Last_corn    High_corn     Low_corn  \\\n",
              "count     1396.000000  1396.000000  1396.000000  1396.000000  1396.000000   \n",
              "unique            NaN          NaN          NaN          NaN          NaN   \n",
              "top               NaN          NaN          NaN          NaN          NaN   \n",
              "freq              NaN          NaN          NaN          NaN          NaN   \n",
              "mean     48992.016476     6.274355   224.952364   227.177113   222.804979   \n",
              "std      62312.826674     3.386027    28.609813    29.061847    27.950594   \n",
              "min          2.000000     1.000000   174.750000   175.750000   174.000000   \n",
              "25%        496.000000     3.000000   206.000000   207.750000   204.750000   \n",
              "50%      11953.000000     6.000000   218.000000   220.000000   215.500000   \n",
              "75%      83600.750000     9.000000   237.750000   239.750000   235.500000   \n",
              "max     253662.000000    12.000000   330.500000   335.250000   329.000000   \n",
              "\n",
              "          Volume_corn  Open_Interest_corn         TAVG           gdp  \\\n",
              "count     1396.000000         1396.000000  1396.000000   1396.000000   \n",
              "unique            NaN                 NaN          NaN           NaN   \n",
              "top               NaN                 NaN          NaN           NaN   \n",
              "freq              NaN                 NaN          NaN           NaN   \n",
              "mean     32740.053009       150963.580946    49.231375  10839.078510   \n",
              "std      20566.028123       104003.747021    19.798379    789.261278   \n",
              "min          3.000000           58.000000    -5.000000   9697.200000   \n",
              "25%      18599.250000        55380.250000    34.000000  10221.600000   \n",
              "50%      31581.500000       157563.500000    51.000000  10572.300000   \n",
              "75%      43074.750000       225783.500000    66.000000  11447.800000   \n",
              "max     180995.000000       394859.000000    83.000000  12589.600000   \n",
              "\n",
              "                cpi          int      nettrade      Weekday  \n",
              "count   1396.000000  1396.000000   1396.000000  1396.000000  \n",
              "unique          NaN          NaN           NaN          NaN  \n",
              "top             NaN          NaN           NaN          NaN  \n",
              "freq            NaN          NaN           NaN          NaN  \n",
              "mean       0.930911     2.844427 -39704.636103     2.017908  \n",
              "std        0.034888     1.951549   9664.234832     1.399578  \n",
              "min        0.870493     0.980000 -58819.000000     0.000000  \n",
              "25%        0.907873     1.260000 -46484.000000     1.000000  \n",
              "50%        0.927843     1.760000 -36519.000000     2.000000  \n",
              "75%        0.958054     4.210000 -31150.750000     3.000000  \n",
              "max        0.997994     6.540000 -26839.000000     4.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "aSpJh9PeNXpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add Year as a feature"
      ]
    },
    {
      "metadata": {
        "id": "1Mf-Xi_gNZV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Year'] = pd.DatetimeIndex(concat_clean['Date']).year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKCTqTq8NQUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deleting Date as a feature"
      ]
    },
    {
      "metadata": {
        "id": "AF3q5KMhNdFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean = concat_clean.drop(['Date'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5rpejR73cEb",
        "colab_type": "code",
        "outputId": "73dee2eb-902a-4bcf-832b-70a816e4da39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "concat_clean.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_Interest</th>\n",
              "      <th>Month</th>\n",
              "      <th>Last_corn</th>\n",
              "      <th>High_corn</th>\n",
              "      <th>Low_corn</th>\n",
              "      <th>Volume_corn</th>\n",
              "      <th>Open_Interest_corn</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>gdp</th>\n",
              "      <th>cpi</th>\n",
              "      <th>int</th>\n",
              "      <th>nettrade</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>282.399994</td>\n",
              "      <td>282.8</td>\n",
              "      <td>280.2</td>\n",
              "      <td>26026.0</td>\n",
              "      <td>67505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>203.00</td>\n",
              "      <td>37490.0</td>\n",
              "      <td>216368.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282.899994</td>\n",
              "      <td>284.5</td>\n",
              "      <td>282.0</td>\n",
              "      <td>19396.0</td>\n",
              "      <td>68731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>202.50</td>\n",
              "      <td>46637.0</td>\n",
              "      <td>219250.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>282.700012</td>\n",
              "      <td>283.9</td>\n",
              "      <td>281.8</td>\n",
              "      <td>11612.0</td>\n",
              "      <td>66778.0</td>\n",
              "      <td>1</td>\n",
              "      <td>208.50</td>\n",
              "      <td>209.25</td>\n",
              "      <td>204.75</td>\n",
              "      <td>47788.0</td>\n",
              "      <td>218442.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>284.399994</td>\n",
              "      <td>285.3</td>\n",
              "      <td>281.9</td>\n",
              "      <td>30928.0</td>\n",
              "      <td>64731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>207.25</td>\n",
              "      <td>209.25</td>\n",
              "      <td>206.25</td>\n",
              "      <td>41233.0</td>\n",
              "      <td>218977.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>283.700012</td>\n",
              "      <td>285.0</td>\n",
              "      <td>282.5</td>\n",
              "      <td>13678.0</td>\n",
              "      <td>64629.0</td>\n",
              "      <td>1</td>\n",
              "      <td>215.50</td>\n",
              "      <td>216.75</td>\n",
              "      <td>206.75</td>\n",
              "      <td>122388.0</td>\n",
              "      <td>229517.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Price   High    Low   Volume  Open_Interest  Month  Last_corn  \\\n",
              "0  282.399994  282.8  280.2  26026.0        67505.0      1     203.75   \n",
              "1  282.899994  284.5  282.0  19396.0        68731.0      1     203.75   \n",
              "2  282.700012  283.9  281.8  11612.0        66778.0      1     208.50   \n",
              "3  284.399994  285.3  281.9  30928.0        64731.0      1     207.25   \n",
              "4  283.700012  285.0  282.5  13678.0        64629.0      1     215.50   \n",
              "\n",
              "   High_corn  Low_corn  Volume_corn  Open_Interest_corn  TAVG     gdp  \\\n",
              "0     205.75    203.00      37490.0            216368.0  30.0  9697.2   \n",
              "1     205.75    202.50      46637.0            219250.0  24.0  9697.2   \n",
              "2     209.25    204.75      47788.0            218442.0  40.0  9697.2   \n",
              "3     209.25    206.25      41233.0            218977.0  40.0  9697.2   \n",
              "4     216.75    206.75     122388.0            229517.0  29.0  9697.2   \n",
              "\n",
              "        cpi   int  nettrade  Weekday  Year  \n",
              "0  0.870493  5.73  -29930.0        3  2000  \n",
              "1  0.870493  5.73  -29930.0        4  2000  \n",
              "2  0.870493  5.73  -29930.0        0  2000  \n",
              "3  0.870493  5.73  -29930.0        1  2000  \n",
              "4  0.870493  5.73  -29930.0        2  2000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "B7nRop-t5llh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up training data"
      ]
    },
    {
      "metadata": {
        "id": "RzoETlC25pXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "List categorical and continuous variables"
      ]
    },
    {
      "metadata": {
        "id": "4rUeCbaD8A2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to use categorical variables, we use entity embedding to find distributed representation of categorical data\n",
        "\n",
        "For this we use min(50, size(var)//2)\n",
        "\n",
        "So month => 6, Date =>50, and Month_Year => 3\n"
      ]
    },
    {
      "metadata": {
        "id": "h1bbjoSfKvhd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because financial data is often heavy-tailed, instead of looking at the price of gold, we can look at the log of the price\n",
        "\n",
        "Creating Log of price"
      ]
    },
    {
      "metadata": {
        "id": "a54O4TDV8Ut5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Log_Price'] = np.log(concat_clean['Price'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWlPM6NvLk7z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean['Log_Price'] = concat_clean['Log_Price'].astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crZ7rlidK_HB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean = concat_clean.drop(['Price'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fvEIigesK3cE",
        "colab_type": "code",
        "outputId": "29e8c12f-c1af-4218-c65d-09765d25ed87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "concat_clean.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_Interest</th>\n",
              "      <th>Month</th>\n",
              "      <th>Last_corn</th>\n",
              "      <th>High_corn</th>\n",
              "      <th>Low_corn</th>\n",
              "      <th>Volume_corn</th>\n",
              "      <th>Open_Interest_corn</th>\n",
              "      <th>TAVG</th>\n",
              "      <th>gdp</th>\n",
              "      <th>cpi</th>\n",
              "      <th>int</th>\n",
              "      <th>nettrade</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Year</th>\n",
              "      <th>Log_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>282.8</td>\n",
              "      <td>280.2</td>\n",
              "      <td>26026.0</td>\n",
              "      <td>67505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>203.00</td>\n",
              "      <td>37490.0</td>\n",
              "      <td>216368.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.643324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284.5</td>\n",
              "      <td>282.0</td>\n",
              "      <td>19396.0</td>\n",
              "      <td>68731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>203.75</td>\n",
              "      <td>205.75</td>\n",
              "      <td>202.50</td>\n",
              "      <td>46637.0</td>\n",
              "      <td>219250.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.645093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>283.9</td>\n",
              "      <td>281.8</td>\n",
              "      <td>11612.0</td>\n",
              "      <td>66778.0</td>\n",
              "      <td>1</td>\n",
              "      <td>208.50</td>\n",
              "      <td>209.25</td>\n",
              "      <td>204.75</td>\n",
              "      <td>47788.0</td>\n",
              "      <td>218442.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.644386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>285.3</td>\n",
              "      <td>281.9</td>\n",
              "      <td>30928.0</td>\n",
              "      <td>64731.0</td>\n",
              "      <td>1</td>\n",
              "      <td>207.25</td>\n",
              "      <td>209.25</td>\n",
              "      <td>206.25</td>\n",
              "      <td>41233.0</td>\n",
              "      <td>218977.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.650382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>285.0</td>\n",
              "      <td>282.5</td>\n",
              "      <td>13678.0</td>\n",
              "      <td>64629.0</td>\n",
              "      <td>1</td>\n",
              "      <td>215.50</td>\n",
              "      <td>216.75</td>\n",
              "      <td>206.75</td>\n",
              "      <td>122388.0</td>\n",
              "      <td>229517.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>9697.2</td>\n",
              "      <td>0.870493</td>\n",
              "      <td>5.73</td>\n",
              "      <td>-29930.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.647917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    High    Low   Volume  Open_Interest  Month  Last_corn  High_corn  \\\n",
              "0  282.8  280.2  26026.0        67505.0      1     203.75     205.75   \n",
              "1  284.5  282.0  19396.0        68731.0      1     203.75     205.75   \n",
              "2  283.9  281.8  11612.0        66778.0      1     208.50     209.25   \n",
              "3  285.3  281.9  30928.0        64731.0      1     207.25     209.25   \n",
              "4  285.0  282.5  13678.0        64629.0      1     215.50     216.75   \n",
              "\n",
              "   Low_corn  Volume_corn  Open_Interest_corn  TAVG     gdp       cpi   int  \\\n",
              "0    203.00      37490.0            216368.0  30.0  9697.2  0.870493  5.73   \n",
              "1    202.50      46637.0            219250.0  24.0  9697.2  0.870493  5.73   \n",
              "2    204.75      47788.0            218442.0  40.0  9697.2  0.870493  5.73   \n",
              "3    206.25      41233.0            218977.0  40.0  9697.2  0.870493  5.73   \n",
              "4    206.75     122388.0            229517.0  29.0  9697.2  0.870493  5.73   \n",
              "\n",
              "   nettrade  Weekday  Year  Log_Price  \n",
              "0  -29930.0        3  2000   5.643324  \n",
              "1  -29930.0        4  2000   5.645093  \n",
              "2  -29930.0        0  2000   5.644386  \n",
              "3  -29930.0        1  2000   5.650382  \n",
              "4  -29930.0        2  2000   5.647917  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "4M0m3X8R5oJD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_vars = ['Year', 'Month', 'Weekday']\n",
        "cont_vars = ['High', 'Low', 'Volume', 'Open_Interest', 'Last_corn', 'High_corn', 'Low_corn',\n",
        "            'Volume_corn', 'Open_Interest_corn', 'TAVG', 'gdp', 'cpi', 'int', 'nettrade']\n",
        "dep_var = 'Log_Price'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "El9iawnk5JG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_clean[dep_var]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cck4TWxOzYR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting into Train/Val set\n",
        "\n",
        "Since we're working with time series data, the rule of thumb is typically to reserve the last 20% of training data for validation"
      ]
    },
    {
      "metadata": {
        "id": "3ipMHQU94zEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_size = len(concat_clean)\n",
        "train_ratio = 0.8\n",
        "train_size = int(sample_size * train_ratio); train_size\n",
        "val_idx = list(range(train_size, len(concat_clean)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AAPeFxk15Nbb",
        "colab_type": "code",
        "outputId": "f2dec9e6-aee5-40f6-dfd4-66c84af6dd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_size)\n",
        "print(len(val_idx))\n",
        "print(train_size+len(val_idx))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1116\n",
            "280\n",
            "1396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xH5qUs29621C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df, valid_df = concat_clean[:train_size].copy(),concat_clean[train_size:].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xci54idyUG4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmu2I1aD-VvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning\n",
        "\n",
        "We can evaluate the performance of the model using Root Mean Square Percentage Error (RMSPE)\n",
        "\n",
        "This is a good metric to evaluate the performance of the model because we want penalize values that are more off more harshly (i.e. a big difference in predicted and actual price is more harmful to the investor than a small difference)\n",
        "\n",
        "Because we are using the log(Price) in our data, we need to take exp(RMSPE)"
      ]
    },
    {
      "metadata": {
        "id": "mO1oZJFg7gp9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "defining variable transformations"
      ]
    },
    {
      "metadata": {
        "id": "aUCT0nXX7jbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = [Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0zz91V8719r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "setting up databunch api from fastai"
      ]
    },
    {
      "metadata": {
        "id": "uEeecamOSEtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??TabularDataBunch.from_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imNpbG9nSL2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??DataBunch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zxeySNLr59wT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??TabularList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jayMJ4Qf6DAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??TabularList.label_from_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8L5Po3pz4E9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 128\n",
        "\n",
        "# data = (TabularList.from_df(concat_clean, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=tfms)\n",
        "#                    .split_by_idx(val_idx)\n",
        "#                    .label_from_df(cols=dep_var, label_cls=F)\n",
        "#                    .databunch(bs = bs))\n",
        "\n",
        "data = (TabularList.from_df(concat_clean, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=tfms)\n",
        "                   .split_by_idx(val_idx)\n",
        "                   .label_from_df(cols=dep_var, label_cls=FloatList, log=True)\n",
        "                   .databunch(bs = bs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KuZ6OkNK74E9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(data, layers = [1000,500], emb_drop = 0.05, metrics = [exp_rmspe], ps = [0.5, 0.5])\n",
        "\n",
        "# learn = tabular_learner(data, layers = [1000,500], emb_szs = {'Year':3, 'Month':6, 'Month_Year':34},\n",
        "#                            metrics = [exp_rmspe], ps = [0.5, 0.5])\n",
        "\n",
        "    \n",
        "# learn = get_tabular_learner(data, layers = [1000,500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3qhi9OYf1ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "eaebb82f-5499-4dae-dc95-15f2e14389bc"
      },
      "cell_type": "code",
      "source": [
        "learn.model"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(6, 4)\n",
              "    (1): Embedding(13, 7)\n",
              "    (2): Embedding(6, 4)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.05)\n",
              "  (bn_cont): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=29, out_features=1000, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=1000, out_features=500, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5)\n",
              "    (8): Linear(in_features=500, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "jwSJaNhuI87x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "finding optimal learning rate"
      ]
    },
    {
      "metadata": {
        "id": "FZXEtRPL9-xQ",
        "colab_type": "code",
        "outputId": "866a9226-e8b7-43cb-d60b-04f83c8fe1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        }
      },
      "cell_type": "code",
      "source": [
        "lr_find(learn)\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='9' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      75.00% [9/12 00:02<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>exp_rmspe</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.230124</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>3.290069</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>3.277333</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>3.249002</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>3.246555</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>3.202006</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>2.967995</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>2.493291</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>2.654745</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='9', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRpkmCL3GGAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2d48d1dac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mR_0CKmEJlOE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "it looks like range between 2e-03 and 1e-02 is a good learning rate to use"
      ]
    },
    {
      "metadata": {
        "id": "qKp32Fl6MJDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('stage-0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YA_Auxq6NHy3",
        "colab_type": "code",
        "outputId": "f58ba4fa-5f21-4b2b-a451-8add1aaa69dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "cell_type": "code",
      "source": [
        "learn.load('stage-0')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(data=DataBunch;\n",
              "Train: LabelList\n",
              "y: CategoryList (1116 items)\n",
              "[5.643324375152588 5.6450934410095215 5.644386291503906 5.650381565093994 ... 5.976350784301758 5.978885650634766\n",
              " 5.978885650634766 5.999184608459473]\n",
              "Path: .\n",
              "x: TabularList (1116 items)\n",
              "[0 1 2 3 ... 1112 1113 1114 1115]\n",
              "Path: /content/data;\n",
              "Valid: LabelList\n",
              "y: CategoryList (280 items)\n",
              "[5.998688220977783 5.993961334228516 5.973300457000732 5.973809719085693 ... 6.05420446395874 6.048553466796875\n",
              " 6.051618576049805 6.057720184326172]\n",
              "Path: .\n",
              "x: TabularList (280 items)\n",
              "[0 1 2 3 ... 276 277 278 279]\n",
              "Path: /content/data;\n",
              "Test: None, model=TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(6, 3)\n",
              "    (1): Embedding(13, 6)\n",
              "    (2): Embedding(6, 4)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.0)\n",
              "  (bn_cont): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=1000, out_features=500, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5)\n",
              "    (8): Linear(in_features=500, out_features=701, bias=True)\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function cross_entropy at 0x7fcc04f46d08>, metrics=[<function exp_rmspe at 0x7fcc0450a730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/data'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
              "  (0): Embedding(6, 3)\n",
              "  (1): Embedding(13, 6)\n",
              "  (2): Embedding(6, 4)\n",
              "  (3): Dropout(p=0.0)\n",
              "  (4): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (5): Linear(in_features=27, out_features=1000, bias=True)\n",
              "  (6): ReLU(inplace)\n",
              "  (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (8): Dropout(p=0.5)\n",
              "  (9): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (10): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): Dropout(p=0.5)\n",
              "  (12): Linear(in_features=500, out_features=701, bias=True)\n",
              ")])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "77kbFvldJghP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-03"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddlRqF80Js_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit the NN"
      ]
    },
    {
      "metadata": {
        "id": "S3hmn6NqJpCk",
        "colab_type": "code",
        "outputId": "dd63437f-ba36-4e7b-e015-e694b99a569e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1575
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(20, slice(lr))\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/20 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>exp_rmspe</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-5fa6015af50f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     19\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 162\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_dl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,\n\u001b[0;32m---> 89\u001b[0;31m                                        cb_handler=cb_handler, pbar=pbar)\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_size1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py\", line 92, in data_collate\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 232, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 232, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 234, in default_collate\n    raise TypeError((error_msg.format(type(batch[0]))))\nTypeError: batch must contain tensors, numbers, dicts or lists; found <class 'NoneType'>\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NYQCiqOzJzi2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "plotting training loss (blue) and val loss (green)\n",
        "\n",
        "- should see loss increase a littel bit, then start to decrease\n",
        "- if loss is always decreasing, means we can probably increase the lr "
      ]
    },
    {
      "metadata": {
        "id": "whzlm4umM-40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "saving model - stage 1"
      ]
    },
    {
      "metadata": {
        "id": "vijq2Nq5J2FU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('stage-1') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLcECsMxv0Eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('stage-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkhwIJu8v4Kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "divide lr by 5, experiment with different weight decay values\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yZY4DPBSv1_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(20, slice(lr/5), wd = 5e-03)\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oO5vMd2Gvzit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "save model stage-2"
      ]
    },
    {
      "metadata": {
        "id": "rGHiW37pNFft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#learn.save('lr5e-02_20epochs') #exp_rmspe = 0.035\n",
        "learn.save('stage2') #exp_rmspe = 0.0178"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7NNbUZ0Qh-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "After tuning the hyperparameters, the NN was able to achieve a validation Root Mean Square Percentage Error of 0.0178"
      ]
    },
    {
      "metadata": {
        "id": "7ofWSsEhSbN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tree-based Ensemble Classifiers\n",
        "\n",
        "For ensemble classifiers, we mainly focus on Random Forests. GBM's are typically more prone to overfitting to noise, due to the nature of the boosting meta-algorithm.\n",
        "\n",
        "By comparison, since Random Forests use bagging, they are typically more robust to variance in data.\n",
        "\n",
        "Because financial data is typically noisy and unstructured, we can expect there to be noise in the data, which makes RF more attractive option to predict our data compared to GBMs\n",
        "\n",
        "In the [Two Sigma Financial Modelling Challenge](http://blog.kaggle.com/2017/05/25/two-sigma-financial-modeling-challenge-winners-interview-2nd-place-nima-shahbazi-chahhou-mohamed/), the 2nd place solution did not use GMBs in the final model"
      ]
    },
    {
      "metadata": {
        "id": "57hieAHnSd_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGkzNzCqTr6N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_6wOl1SgTiIu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df_y = train_df['Log_Price']\n",
        "valid_df_y = valid_df['Log_Price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JHxKHeMTzGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df_rf = train_df.drop(['Log_Price'], axis = 1)\n",
        "valid_df_rf = valid_df.drop(['Log_Price'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dRKtpxDsTz-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# defining function to evaluate exp_rmspe\n",
        "def inv_y(a): return np.exp(a)\n",
        "\n",
        "def exp_rmspe(y_pred, targ):\n",
        "    targ = inv_y(targ)\n",
        "    pct_var = (targ - inv_y(y_pred))/targ\n",
        "    return math.sqrt((pct_var**2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjfFwoQDU2oz",
        "colab_type": "code",
        "outputId": "16914be5-79b4-441f-e59a-1f2eb01a3499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "m = RandomForestRegressor(n_estimators=100, max_features=0.99, min_samples_leaf=2,\n",
        "                          n_jobs=-1, oob_score=True)\n",
        "m.fit(train_df_rf, train_df_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features=0.99, max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=2, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "yZSYcdgaU-sm",
        "colab_type": "code",
        "outputId": "9132960a-ead3-400f-c61f-12fcc77413d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "preds = m.predict(valid_df_rf)\n",
        "exp_rmspe(preds, valid_df_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019217474767001155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "c6FaGfNqP5Md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}